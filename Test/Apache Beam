// Step 5: Truncate the repeat_usage table
PCollection<String> truncateResults = pipeline
    .apply("Truncate Table", DatabaseOperationUtility.truncateTable(
        QueryFieldUtils.QUERY_TRUNCATE_REPEAT_USAGE.getQuery()));

// Step 6: Write RepeatUse objects to the database after truncate completes
PCollection<String> dbWritingResults = repeatUseObj
    .apply("Wait for Truncate", Wait.on(truncateResults))
    .apply("Write RepeatUse to DB", DatabaseOperationUtility.writeToDatabaseWithStatus(
        QueryFieldUtils.REPEAT_USE_INSERT.getQuery(), RepeatUse.class));

// Step 7: Update the customer_account table after write completes
PCollection<String> customerUpdateResults = dbWritingResults
    .apply("Update Customer Table", ParDo.of(new DoFn<String, String>() {
        @ProcessElement
        public void processElement(ProcessContext context) {
            DatabaseOperationUtility.updateTable(
                QueryFieldUtils.QUERY_UPDATE_CUSTOMER_ACCOUNT.getQuery());
            context.output("Customer Table Updated");
        }
    }));

// Step 8: Get inserted record count from DB after customer update
PCollectionView<Long> processedCountView = customerUpdateResults
    .apply("Fetch Inserted Record Count", ParDo.of(new DoFn<String, Long>() {
        @ProcessElement
        public void processElement(ProcessContext context) {
            long count = DatabaseOperationUtility.getInsertedRecordsCount(
                QueryFieldUtils.REPEAT_USE_COUNT.getQuery());
            context.output(count);
        }
    })).apply(View.asSingleton());

// Step 9: Update job status only after record count is retrieved
pipeline.apply("Update Job Status", ParDo.of(new DoFn<Void, Void>() {
    @ProcessElement
    public void processElement(ProcessContext c) {
        long count = c.sideInput(processedCountView);
        DatabaseOperationUtility.updateJobStatus(
            JobConfig.REPEAT_USE_DAILY_PROC_JOB, "sourceCount", count, USRConstants.COMPLETED);
    }
}).withSideInputs(processedCountView));



import org.apache.beam.sdk.Pipeline;
import org.apache.beam.sdk.io.TextIO;
import org.apache.beam.sdk.testing.PAssert;
import org.apache.beam.sdk.testing.TestPipeline;
import org.apache.beam.sdk.values.PCollection;
import org.junit.Rule;
import org.junit.jupiter.api.Test;
import org.junit.jupiter.api.io.TempDir;
import org.mockito.Mockito;

import java.io.File;
import java.io.FileWriter;
import java.nio.file.Path;

import static org.junit.jupiter.api.Assertions.assertDoesNotThrow;
import static org.junit.jupiter.api.Assertions.assertNotNull;

public class RepeatUseDailyNormTest {

    @TempDir
    Path tempDir;

    // Optional if you want to use @Rule style (JUnit 4 compatibility)
    @Rule
    public final transient TestPipeline testPipeline = TestPipeline.create();

    @Test
    void testCreatePipelineReadsFileWithTestPipeline() throws Exception {
        // Step 1: Prepare test input file
        File testFile = tempDir.resolve("test-input.txt").toFile();
        try (FileWriter writer = new FileWriter(testFile)) {
            writer.write("first\nsecond\nthird\n");
        }

        // Step 2: Mock the LogErrorFileUtility
        LogErrorFileUtility mockLogUtil = Mockito.mock(LogErrorFileUtility.class);

        // Step 3: Use TestPipeline directly
        Pipeline pipeline = TestPipeline.create();

        // Step 4: Apply read
        PCollection<String> output = pipeline.apply(
                "READ_HOTORU_FILE", TextIO.read().from(testFile.getAbsolutePath())
        );

        // Step 5: Assert
        PAssert.that(output).containsInAnyOrder("first", "second", "third");

        pipeline.run().waitUntilFinish();
    }

    @Test
    void testMainRunsWithoutErrors() {
        assertDoesNotThrow(() -> Test.main(new String[]{}));
    }

    @Test
    void testCreatePipelineReturnsNonNullPipeline() {
        LogErrorFileUtility mockLogUtil = Mockito.mock(LogErrorFileUtility.class);
        Pipeline pipeline = Test.createPipeline(mockLogUtil, "/dummy/path.txt");
        assertNotNull(pipeline);
    }
}



import org.apache.beam.sdk.testing.PAssert;
import org.apache.beam.sdk.testing.TestPipeline;
import org.apache.beam.sdk.transforms.Filter;
import org.apache.beam.sdk.io.FileSystems;
import org.apache.beam.sdk.io.fs.MatchResult;
import org.apache.beam.sdk.io.TextIO;
import org.apache.beam.sdk.transforms.Create;
import org.apache.beam.sdk.values.PCollection;
import org.apache.beam.sdk.Pipeline;
import org.apache.beam.sdk.coders.StringUtf8Coder;
import org.junit.Rule;
import org.junit.Test;
import org.junit.runner.RunWith;
import org.mockito.MockedStatic;
import org.mockito.junit.MockitoJUnitRunner;

import java.io.FileNotFoundException;
import java.io.IOException;
import java.util.Arrays;
import java.util.List;

import static org.mockito.Mockito.*;

@RunWith(MockitoJUnitRunner.class)
public class FileReaderPipelineTest {

    @Rule
    public final transient TestPipeline pipeline = TestPipeline.create();

    @Test
    public void testCreatePipeline_FileExists_FiltersHeaderLines() throws IOException {
        String mockPath = "mock/input.txt";
        List<String> mockLines = Arrays.asList("Header1", "Body", "Header2", "Trailer");

        // Mocking FileSystems.matchSingleFileSpec
        try (MockedStatic<FileSystems> fsMock = mockStatic(FileSystems.class)) {
            MatchResult.Metadata mockMeta = mock(MatchResult.Metadata.class);
            fsMock.when(() -> FileSystems.matchSingleFileSpec(mockPath)).thenReturn(mockMeta);

            // Instead of real TextIO, mock with Create.of
            PCollection<String> input = pipeline.apply(Create.of(mockLines).withCoder(StringUtf8Coder.of()));
            PCollection<String> filtered = input.apply(Filter.by(line -> line != null && line.trim().startsWith("H")));

            PAssert.that(filtered).containsInAnyOrder("Header1", "Header2");
            pipeline.run().waitUntilFinish();
        }
    }

    @Test(expected = FileNotFoundException.class)
    public void testCreatePipeline_FileDoesNotExist_ThrowsException() throws IOException {
        String mockPath = "nonexistent.txt";

        try (MockedStatic<FileSystems> fsMock = mockStatic(FileSystems.class)) {
            fsMock.when(() -> FileSystems.matchSingleFileSpec(mockPath)).thenReturn(null);

            Pipeline testPipe = Pipeline.create();
            FileReaderPipeline.createPipeline(testPipe, mockPath);
        }
    }
}


import org.apache.beam.sdk.transforms.DoFn;
import org.apache.beam.sdk.values.TupleTag;
import org.apache.beam.sdk.values.KV;
import org.apache.beam.sdk.values.Row;
import org.apache.beam.sdk.transforms.DoFnTester;
import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.Test;
import java.util.HashMap;
import java.util.Map;

import static org.junit.jupiter.api.Assertions.*;

public class RepeatUseNormalizationConversionTest {

    private RepeatUseNormalizationConversion fn;
    private TupleTag<String> logTag;
    private TupleTag<Row> validTag;

    @BeforeEach
    public void setup() {
        logTag = new TupleTag<>();
        validTag = new TupleTag<>();
        fn = new RepeatUseNormalizationConversion(logTag, validTag);
    }

    @Test
    public void testValidInput() throws Exception {
        Map<String, Object> values = new HashMap<>();
        values.put("HOTROU-ACCOUNT-NBR", "123456789");
        values.put("HOTROU-REPT-USE-IND-1", "Y");
        values.put("HOTROU-REPT-USE-DATE-1", "20230501");
        values.put("HOTROU-REPT-USE-IND-2", "N");
        values.put("HOTROU-REPT-USE-DATE-2", "20230502");
        values.put("HOTROU-REPT-USE-IND-3", "Y");
        values.put("HOTROU-REPT-USE-DATE-3", "20230503");
        values.put("HOTROU-REPT-USE-HISTORY", "Some history");

        Row inputRow = Row.withSchema(RepeatUseSchema.ROW_SCHEMA).addValues(
                values.get("HOTROU-ACCOUNT-NBR"),
                values.get("HOTROU-REPT-USE-IND-1"),
                values.get("HOTROU-REPT-USE-DATE-1"),
                values.get("HOTROU-REPT-USE-IND-2"),
                values.get("HOTROU-REPT-USE-DATE-2"),
                values.get("HOTROU-REPT-USE-IND-3"),
                values.get("HOTROU-REPT-USE-DATE-3"),
                values.get("HOTROU-REPT-USE-HISTORY")
        ).build();

        DoFnTester<Row, Row> tester = DoFnTester.of(fn);
        tester.processElement(inputRow);

        assertEquals(1, tester.peekOutput(validTag).size());
        assertTrue(tester.peekOutput(logTag).isEmpty());
    }

    @Test
    public void testInvalidAccountNumber() {
        Map<String, Object> values = new HashMap<>();
        values.put("HOTROU-ACCOUNT-NBR", "");
        values.put("HOTROU-REPT-USE-IND-1", "Y");
        values.put("HOTROU-REPT-USE-DATE-1", "20230501");

        Row inputRow = Row.withSchema(RepeatUseSchema.ROW_SCHEMA).addValues(
                values.get("HOTROU-ACCOUNT-NBR"),
                values.get("HOTROU-REPT-USE-IND-1"),
                values.get("HOTROU-REPT-USE-DATE-1"),
                "", "", "", "", ""
        ).build();

        DoFnTester<Row, Row> tester = DoFnTester.of(fn);
        tester.processElement(inputRow);

        assertEquals(0, tester.peekOutput(validTag).size());
        assertEquals(1, tester.peekOutput(logTag).size());
    }

    @Test
    public void testInvalidDateFormat() {
        Map<String, Object> values = new HashMap<>();
        values.put("HOTROU-ACCOUNT-NBR", "987654321");
        values.put("HOTROU-REPT-USE-IND-1", "Y");
        values.put("HOTROU-REPT-USE-DATE-1", "invalid-date");

        Row inputRow = Row.withSchema(RepeatUseSchema.ROW_SCHEMA).addValues(
                values.get("HOTROU-ACCOUNT-NBR"),
                values.get("HOTROU-REPT-USE-IND-1"),
                values.get("HOTROU-REPT-USE-DATE-1"),
                "", "", "", "", ""
        ).build();

        DoFnTester<Row, Row> tester = DoFnTester.of(fn);
        tester.processElement(inputRow);

        assertEquals(1, tester.peekOutput(validTag).size()); // with DEFAULT_DATE fallback
        assertFalse(tester.peekOutput(logTag).isEmpty());
    }
}



import static org.mockito.Mockito.*;

import org.apache.beam.sdk.Pipeline;
import org.apache.beam.sdk.options.PipelineOptionsFactory;
import org.apache.beam.sdk.testing.TestPipeline;
import org.junit.Rule;
import org.junit.Test;
import org.junit.runner.RunWith;
import org.mockito.MockedStatic;
import org.mockito.junit.MockitoJUnitRunner;
import org.slf4j.Logger;

@RunWith(MockitoJUnitRunner.class)
public class YourMainClassTest {

    @Rule
    public final TestPipeline testPipeline = TestPipeline.create();

    @Test
    public void testMainMethod() {
        try (
            MockedStatic<PipelineOptionsFactory> factoryMock = mockStatic(PipelineOptionsFactory.class);
            MockedStatic<Pipeline> pipelineMock = mockStatic(Pipeline.class)
        ) {
            CustomPipelineOptions mockOptions = mock(CustomPipelineOptions.class);
            Pipeline mockPipeline = mock(Pipeline.class);

            factoryMock.when(() -> PipelineOptionsFactory.create()).thenReturn(mockOptions);
            when(mockOptions.as(CustomPipelineOptions.class)).thenReturn(mockOptions);
            when(mockOptions.getInputFileName()).thenReturn("mock_input");
            when(mockOptions.getGcsInputFileBasePath()).thenReturn("mock_base_path");
            when(mockOptions.getOutputFileBasePath()).thenReturn("mock_output_path");
            when(mockOptions.getOutputFileName()).thenReturn("mock_file_name");

            pipelineMock.when(() -> Pipeline.create(mockOptions)).thenReturn(mockPipeline);
            when(mockPipeline.run()).thenReturn(testPipeline.run());

            YourMainClass.main(new String[]{});

            verify(mockPipeline.run()).waitUntilFinish();
        } catch (Exception e) {
            throw new AssertionError("Test failed", e);
        }
    }
}

import static org.mockito.Mockito.*;

import org.apache.beam.sdk.Pipeline;
import org.apache.beam.sdk.options.PipelineOptionsFactory;
import org.apache.beam.sdk.testing.TestPipeline;
import org.junit.Rule;
import org.junit.Test;

public class YourMainClassTest {

    @Rule
    public final TestPipeline testPipeline = TestPipeline.create();

    @Test
    public void testMainMethod() {
        try (
            MockedStatic<PipelineOptionsFactory> factoryMock = mockStatic(PipelineOptionsFactory.class);
            MockedStatic<Pipeline> pipelineMock = mockStatic(Pipeline.class)
        ) {
            CustomPipelineOptions mockOptions = mock(CustomPipelineOptions.class);
            Pipeline mockPipeline = mock(Pipeline.class);

            // Set up mock behavior
            factoryMock.when(PipelineOptionsFactory::create).thenReturn(mockOptions);
            when(mockOptions.as(CustomPipelineOptions.class)).thenReturn(mockOptions);

            when(mockOptions.getInputFileName()).thenReturn("mock_input");
            when(mockOptions.getGcsInputFileBasePath()).thenReturn("mock_base_path");
            when(mockOptions.getOutputFileBasePath()).thenReturn("mock_output_path");
            when(mockOptions.getOutputFileName()).thenReturn("mock_file_name");

            pipelineMock.when(() -> Pipeline.create(mockOptions)).thenReturn(mockPipeline);
            when(mockPipeline.run()).thenReturn(testPipeline.run());

            // Run the main method
            YourMainClass.main(new String[]{});

            // Verify that waitUntilFinish was called
            verify(mockPipeline.run()).waitUntilFinish();
        } catch (Exception e) {
            throw new AssertionError("Test failed", e);
        }
    }
}





import com.zaxxer.hikari.HikariConfig;
import com.zaxxer.hikari.HikariDataSource;
import org.apache.beam.sdk.transforms.DoFn;
import org.apache.beam.sdk.transforms.ParDo;
import org.apache.beam.sdk.values.PCollection;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.lang.reflect.Field;
import java.sql.Connection;
import java.sql.PreparedStatement;

public class DbWriteUtil {

    private static final Logger LOG = LoggerFactory.getLogger(DbWriteUtil.class);
    private static HikariDataSource dataSource;

    // Initialize HikariCP once
    public static void initDataSource(String jdbcUrl, String username, String password) {
        if (dataSource == null) {
            HikariConfig config = new HikariConfig();
            config.setJdbcUrl(jdbcUrl);
            config.setUsername(username);
            config.setPassword(password);
            config.setMaximumPoolSize(5);
            dataSource = new HikariDataSource(config);
        }
    }

    // Generic write method
    public static <T> void writeToDb(PCollection<T> collection, String insertQuery) {
        collection.apply("WriteToDB", ParDo.of(new DoFn<T, Void>() {

            private transient Connection connection;
            private transient PreparedStatement preparedStatement;

            @Setup
            public void setup() throws Exception {
                connection = dataSource.getConnection();
                preparedStatement = connection.prepareStatement(insertQuery);
            }

            @ProcessElement
            public void processElement(ProcessContext ctx) {
                T element = ctx.element();
                try {
                    Field[] fields = element.getClass().getDeclaredFields();
                    for (int i = 0; i < fields.length; i++) {
                        fields[i].setAccessible(true);
                        preparedStatement.setObject(i + 1, fields[i].get(element));
                    }
                    preparedStatement.executeUpdate();
                } catch (Exception e) {
                    LOG.error("Failed to insert row: {}", element, e);
                }
            }

            @Teardown
            public void teardown() throws Exception {
                if (preparedStatement != null) preparedStatement.close();
                if (connection != null) connection.close();
            }
        }));
    }
}

